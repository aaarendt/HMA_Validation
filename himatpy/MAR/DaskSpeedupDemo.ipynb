{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupter notebook magic\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from datetime import datetime, timedelta\n",
    "from copy import copy\n",
    "import geopandas as gpd\n",
    "from PyAstronomy import pyasl\n",
    "\n",
    "import zarr\n",
    "import s3fs\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import himatpy, himatpy.GRACE_MASCON.pygrace, himatpy.MAR.utils\n",
    "\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "reload(himatpy.MAR.utils)\n",
    "reload(himatpy.GRACE_MASCON.pygrace)\n",
    "\n",
    "\n",
    "from himatpy.GRACE_MASCON.pygrace import (extract_grace, get_mascon_gdf, masked_mascon_gdf,grace_data_df,\\\n",
    "                                          get_full_trend,trend_analysis, get_cmwe_trend_analysis, select_mascons, \\\n",
    "                                          aggregate_mascons)\n",
    "from himatpy.MAR.utils import save_agg_mascons,  MAR_trend, subset_data, nc2zarr,save_agg_mascons_zarr\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "  * This notebook showcases the improvements in code efficiency by using chunked arrays with dask.\n",
    "\n",
    "  * The aggregation of model data to GRACE mascons also benefits from using the xarray properly and avoid the overhead of its where function. \n",
    "  * This notebook requires the subsetting of MAR data to netcdf first and convert to a zarr store (either on s3 or local) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment and run the cell below if subset data and zarr store have not been created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNAME    = 'MAR'\n",
    "# MAR_locl = os.path.join( os.path.abspath('./Data'), DNAME ) \n",
    "# SUB_locl = os.path.join( os.path.abspath('./SUB') , DNAME ) \n",
    "# marfns   = sorted(glob(MAR_locl+'/*.nc'))\n",
    "# subfns   = sorted(glob(SUB_locl+'/*.nc'))\n",
    "# if not os.path.exists(SUB_locl): os.makedirs(SUB_locl)\n",
    "\n",
    "# # --- subset MAR dataset: around 40s per file.  \n",
    "# chunks = {'X11_210':100,'Y11_190':90} \n",
    "# for ifn, tfn in enumerate(marfns[:1]):\n",
    "#     start_time = timeit.default_timer()\n",
    "#     sdir,sfn = os.path.split(tfn)\n",
    "#     print(ifn,sfn)\n",
    "#     ofn = os.path.join(SUB_locl,sfn)\n",
    "#     subset_data(tfn,ofn,zlib=True,chunks=chunks)\n",
    "#     end_time = timeit.default_timer()\n",
    "#     print('Processing time [s]:',end_time-start_time) \n",
    "\n",
    "# # --- convert subset nc files to zarr: around 2.5 min \n",
    "# # --- cannot overwrite existing zarr store, may need to remove first\n",
    "# chunks = {'time':360,'X':100,'Y':90}\n",
    "# S3_root  = 'pangeo-data-upload-oregon/icesat2/HMA_Validation/'\n",
    "# ZAR_path = os.path.join(S3_root,'ZarrSUB',DNAME)\n",
    "# start_time = timeit.default_timer()\n",
    "# nc2zarr(subfns,ZAR_path,s3store=True,chunks=chunks,parallel=True)\n",
    "# end_time = timeit.default_timer()\n",
    "# print('Processing time [s]:',end_time-start_time) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation: read Grace data to select the mascons in the MAR domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted: \n",
      "... read info of mascons in domain from MAR_mascons.geojson ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/HMA/HMA_Validation/himatpy/GRACE_MASCON/pygrace.py:45: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  f = h5py.File(fpath)\n"
     ]
    }
   ],
   "source": [
    "Grace_fn = 'Data/Grace/GSFC.glb.200301_201607_v02.4-ICE6G.h5'\n",
    "# ---> use local copy\n",
    "grace_file = os.path.abspath(Grace_fn)\n",
    "f = extract_grace(grace_file,printGroups=False)\n",
    "\n",
    "# --- save the GRACE mascon info into file for future access/read if it already exists\n",
    "SNAME    = 'MAR'\n",
    "SUB_locl = os.path.join( os.path.abspath('./SUB') , SNAME ) \n",
    "subfns = sorted(glob(SUB_locl+'/*.nc'))\n",
    "ds = xr.open_dataset(subfns[0])\n",
    "MAR_mascons_fn = 'MAR_mascons.geojson'\n",
    "masked_gdf = masked_mascon_gdf(f,ds,mascons_fn = MAR_mascons_fn,verbose=True)\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the code efficiency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, contrast between the first two options using aggregate_mascons in pygrace. \n",
    "  * read subset MAR data without chunks\n",
    "  * read subset MAR data with chunks\n",
    "\n",
    "Because aggregate_mascons in pygrace has to query through the model data using mascon geometry for every data array in the dataset and loops over all mascons, it becomes extremely slow. For a single subset data file (one year, ~280MB), it takes about 21 min without chunks and dask, and 2 minutes with parallelization with dask. This is still relatively long, we choose 10 mascons out of 370 and demonstrate the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time [s] for option 1: 3.184700108249672e-05\n",
      "... aggregating HMA_MAR3_5_ICE.2000.01-12.h22.nc ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/is2hack/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/home/jovyan/is2hack/lib/python3.8/site-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time [s] for option 2: 132.01944375099993\n"
     ]
    }
   ],
   "source": [
    "mascon10 = masked_gdf#.iloc[:20]\n",
    "# --- This line tests option 1, without chunks. \n",
    "start_time = timeit.default_timer()\n",
    "#save_agg_mascons(subfns[:1],'testagg',mascon10)\n",
    "end_time = timeit.default_timer()\n",
    "print('Processing time [s] for option 1:',end_time-start_time) \n",
    "# --- reset timer and run option 2. \n",
    "start_time = timeit.default_timer()\n",
    "save_agg_mascons(subfns[:1],'testagg',mascon10,chunks=chunks)\n",
    "#save_agg_mascons(subfns[:1],'testagg',mascon10,chunks={'Y':200})\n",
    "end_time = timeit.default_timer()\n",
    "print('Processing time [s] for option 2:',end_time-start_time) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without chunks, 10 mascons take about 35s. Using the chunks defined above (4 chunks in X/Y plane), they take 9s and using chunks but only one chunk in X/Y plane by using `chunks={'Y':200}`, it's actually slightly faster. The recommended chunk size by dask is 100 MB or at least 1M elements. For MAR data, a variable in one year (float32) is only 54 MB. Further chunking likely makes it less efficient. Although with only one chunk in X/Y, plane, dask still parallelize the processing across variables and speeds up the processing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, use the new save_agg_mascon_zarr function in MAR/utils \n",
    "Use 100 mascons. About 1 min is needed for the whole 16-year data. Less than 3 min 41s is needed for all the mascons. \n",
    "The function save_agg_mascon_zarr use indices of MAR grid points in GRACE mascons to aggregate the entire MAR dataset. \n",
    "This avoids repeated calls to `xr.DataArray.where`. Using np.where to find indices to avoid the overhead on `xr.Dataset.where` . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 6.18 s, total: 1min 16s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mascon100 = masked_gdf.iloc[:100]\n",
    "save_agg_mascons_zarr(ds_store,'testagg/aggmar_test.nc',mascon100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (mascon: 92, time: 5844)\n",
      "Coordinates:\n",
      "    SECTOR     float32 ...\n",
      "    SECTOR1_1  float32 ...\n",
      "  * time       (time) datetime64[ns] 2000-01-01 2000-01-02 ... 2015-12-31\n",
      "  * mascon     (mascon) int64 6693 6694 6695 6696 6697 ... 7767 7777 7778 7779\n",
      "Data variables:\n",
      "    RF         (mascon, time) float32 ...\n",
      "    RU_ice     (mascon, time) float32 ...\n",
      "    RU_other   (mascon, time) float32 ...\n",
      "    SF         (mascon, time) float32 ...\n",
      "    SMB_ice    (mascon, time) float32 ...\n",
      "    SMB_other  (mascon, time) float32 ...\n",
      "    SU_ice     (mascon, time) float32 ...\n",
      "    SU_other   (mascon, time) float32 ...\n",
      "    SW_ice     (mascon, time) float32 ...\n",
      "    lat        (mascon) float32 ...\n",
      "    long       (mascon) float32 ...\n"
     ]
    }
   ],
   "source": [
    "with xr.open_dataset('testagg/aggmar_test.nc') as tds:\n",
    "    print(tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another question\n",
    "Why not use `xr.Dataset.where` on the entire dataset? It can be demonstrated by the example below. For 10 mascons, 8s/5s for two choices of chunks. For all 370 mascons and one year, it uses 102s/88s with two choices chunks, slightly faster by 20s than using where on DataArray's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 205 ms, total: 13.1 s\n",
      "Wall time: 8.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#with xr.open_dataset(subfns[0],chunks={'Y':200}) as ds:\n",
    "with xr.open_dataset(subfns[0],chunks=chunks) as ds:\n",
    "    geos = [x.bounds for x in masked_gdf['geometry']]\n",
    "    dslist = []\n",
    "    # len(geos) is 370\n",
    "    for i in range(10):\n",
    "        geo = geos[i]\n",
    "        tds = ds.where( (ds.long>=geo[0]) & (ds.long<=geo[2]) & (ds.lat>=geo[1]) & (ds.lat<= geo[3]) )\n",
    "        dslist.append(tds.mean(axis=(-1,-2)))\n",
    "    nds = xr.concat(dslist,'mascon').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the zarr store for the entire 16 years, about 6 min 23s is needed for 100 mascons. Compare to uisng the function save_agg_mascons_zarr, which takes 1 min for 100 mascons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/is2hack/lib/python3.8/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 21s, sys: 9.21 s, total: 20min 30s\n",
      "Wall time: 6min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fs       = s3fs.S3FileSystem(anon=False)\n",
    "ds_store = s3fs.S3Map(root=ZAR_path,s3=fs,check=True)\n",
    "with xr.open_zarr(ds_store) as ds:\n",
    "    geos = [x.bounds for x in masked_gdf['geometry']]\n",
    "    dslist = []\n",
    "    start_time = timeit.default_timer()\n",
    "    for i in range(100):\n",
    "        geo = geos[i]\n",
    "        tds = ds.where( (ds.long>=geo[0]) & (ds.long<=geo[2]) & (ds.lat>=geo[1]) & (ds.lat<= geo[3]) )\n",
    "        dslist.append(tds.mean(axis=(-1,-2)))\n",
    "    nds = xr.concat(dslist,'mascon').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6 is2hack",
   "language": "python",
   "name": "is2hack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
